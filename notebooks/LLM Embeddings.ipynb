{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724c9b8-08f9-415c-9009-f9dc6e5a1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48e824e-b640-490a-9bd6-7f9191aa03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(os.getenv('COHERE_API_KEY'))\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "anthropic_client = Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0912d3-6324-41a9-9406-3ca303b9c092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b9580-e9bf-429d-8b9f-c28454d0f991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9135eca-9151-4ccf-b612-b7ac105108cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0bd5aa-e05f-48da-9ddc-c13235868a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ba920653e348169b6038eaf9e9e6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d93156937842dc8335a6481fcb710a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c44d68592a4349a69a0044ea2c0e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799a7fa23f484c31aed7929f26067541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b6c9b61627470dad980868b0238458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f289a512a23e4999998f9f7acc45eda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb2957e2c634757b562a8e5d4ea7636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55a8e2540c845a3a6c92c0b4c05a702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9141a273714b9a9777a76e05cbb637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65e3c32bc5c40568039d9106471191d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f5a11344e84d74aa3c4e002c9720fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def get_cosine_similarity(embedding1, embedding2):\n",
    "    # Calculate cosine similarity (note: scipy's cosine function actually computes the distance, so we subtract from 1)\n",
    "    cos_sim = 1 - cosine(embedding1, embedding2)\n",
    "    return cos_sim\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Example sentences\n",
    "sentences = [\"This is an example sentence\", \"This is also an example sentence.\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1, embedding2 = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3096113e-38b6-4a95-84bd-966807b2612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8140869736671448\n"
     ]
    }
   ],
   "source": [
    "# Calculate similarity\n",
    "similarity = get_cosine_similarity(embedding1, embedding2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24953c6d-5641-480e-8c1f-fd13d0387f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b232f03-8dd1-4887-860d-82dd5cb2ba72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.42858582735061646\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I like this\", \"I hate this\"]\n",
    "\n",
    "# Generate embeddings\n",
    "embedding1, embedding2 = model.encode(sentences)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = get_cosine_similarity(embedding1, embedding2)\n",
    "print(\"Cosine Similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe201926-ea91-4cf0-846c-6bdb9b639c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c37299a-89c7-4f60-90a5-10c4bb543803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_word_embedding(sentence, word, model, tokenizer, model_type='bert'):\n",
    "    # Tokenize and encode the sentence\n",
    "    encoded_input = tokenizer(sentence, return_tensors='pt')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "\n",
    "    # Find the index of the word (handling potential subword tokenization)\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    word_index = None\n",
    "    for i in range(len(tokens) - len(word_tokens) + 1):\n",
    "        if tokens[i:i + len(word_tokens)] == word_tokens:\n",
    "            word_index = i\n",
    "            break\n",
    "    if word_index is None:\n",
    "        raise ValueError(f\"Word '{word}' not found in the tokenized sentence.\")\n",
    "\n",
    "    # Get model output\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "\n",
    "    # Extract the embedding for the specified word (for GPT models, take the last layer)\n",
    "    if model_type == 'bert':\n",
    "        word_embedding = output.last_hidden_state[0, word_index, :]\n",
    "    elif model_type == 'gpt':\n",
    "        word_embedding = output['last_hidden_state'][0, word_index, :]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type specified. Choose 'bert' or 'gpt'.\")\n",
    "    \n",
    "    return word_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03769993-e6ed-417c-833a-5a05f76c7493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50505ff6d5f4585b9d9bff4d6d5a46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pre-trained models and tokenizers\n",
    "\n",
    "# For BERT (auto-encoding)\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# For GPT-2 (auto-regressive)\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "gpt_model = AutoModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e1217-b14b-44d8-a499-2f8a4e472632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f161f8d-ed4a-44f2-bbbf-5ca28f279ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Initial Embedding for 'bank': tensor([ 0.0894, -0.5583, -1.3665, -1.0918, -0.3904])\n",
      "GPT-2 Initial Embedding for 'bank': tensor([-0.0123, -0.0829,  0.2273,  0.1093,  0.0301])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "def get_initial_word_embedding(word, tokenizer, model, model_type='bert'):\n",
    "    # Tokenize and encode the word\n",
    "    encoded_input = tokenizer(word, return_tensors='pt')\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoded_input['input_ids'][0])\n",
    "\n",
    "    # Handling the case when a word is split into subwords\n",
    "    if len(tokens) > 3:  # Including special tokens [CLS], [SEP] for BERT or GPT-2\n",
    "        raise ValueError(\"The word was split into subwords. Please provide a single token.\")\n",
    "\n",
    "    # Extract the token index (excluding special tokens)\n",
    "    token_index = 1 if model_type == 'bert' else 0\n",
    "\n",
    "    # Get the embeddings\n",
    "    with torch.no_grad():\n",
    "        if model_type == 'bert':\n",
    "            embeddings = model.embeddings(encoded_input['input_ids'])[0, token_index, :]\n",
    "        elif model_type == 'gpt':\n",
    "            # For GPT-2, manually apply the embedding layer\n",
    "            input_ids = encoded_input['input_ids']\n",
    "            embeddings = model.wte(input_ids)[0, token_index, :]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type specified. Choose 'bert' or 'gpt'.\")\n",
    "\n",
    "    return embeddings\n",
    "    \n",
    "# Example word\n",
    "word = \"bank\"\n",
    "\n",
    "# Get initial embedding for BERT\n",
    "bert_initial_embedding = get_initial_word_embedding(word, bert_tokenizer, bert_model, 'bert')\n",
    "print(\"BERT Initial Embedding for '{}':\".format(word), bert_initial_embedding[:5])\n",
    "\n",
    "# Get initial embedding for GPT-2\n",
    "gpt_initial_embedding = get_initial_word_embedding(word, gpt_tokenizer, gpt_model, 'gpt')\n",
    "print(\"GPT-2 Initial Embedding for '{}':\".format(word), gpt_initial_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07c5af-87b6-41f2-b492-c6a6cc3b5274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da4040c-c6ac-471e-8b56-94af7fdc165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 0.2764, -0.4860,  0.2104, -0.3106, -0.0630])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the river bank for a nice walk.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# Get BERT embedding for bank\n",
    "embedding = get_word_embedding(sentence, word, bert_model, bert_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6707430-fba7-47f2-a769-1b7cb260a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BERT similarity to initial water/money embedding\n",
    "water_embedding = get_initial_word_embedding('water', bert_tokenizer, bert_model, 'bert')\n",
    "money_embedding = get_initial_word_embedding('money', bert_tokenizer, bert_model, 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d59d97-54c5-4c76-8f1a-3f711ef2b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity to BERT(water): 0.06027546897530556\n",
      "Cosine Similarity to BERT(money): 0.004379441495984793\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity to BERT(water):\", get_cosine_similarity(embedding, water_embedding))\n",
    "print(\"Cosine Similarity to BERT(money):\", get_cosine_similarity(embedding, money_embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cff8d1e-4dd3-43be-b417-861583a7e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'bank': tensor([ 0.7613, -0.3984, -0.1457, -0.1107,  1.2720])\n"
     ]
    }
   ],
   "source": [
    "# BERT embeddings for \"bank\" in relation to cash\n",
    "sentence = \"I went to the bank to get some cash out of savings.\"\n",
    "word = \"bank\"\n",
    "\n",
    "# bank has a different embedding\n",
    "embedding = get_word_embedding(sentence, word, bert_model, bert_tokenizer)\n",
    "print(\"Embedding for '{}':\".format(word), embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fcf9e5f-aa0c-4e77-81c5-b2d5c8551497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity to BERT(water): -0.0015438803238794208\n",
      "Cosine Similarity to BERT(money): 0.061874888837337494\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity to BERT(water):\", get_cosine_similarity(embedding, water_embedding))\n",
    "print(\"Cosine Similarity to BERT(money):\", get_cosine_similarity(embedding, money_embedding))\n",
    "\n",
    "# similarity went down compared to water and up for money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa7c6a-bd5a-4683-9269-015824c68212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92a238f-72da-4bc2-9917-f3cc41c4be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For gpt, position matters for embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97117d33-6282-41ac-899a-b9d21ea46312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Embedding for ' bank' in relation to cash: tensor([-0.1299, -0.3162, -1.0468,  0.1864,  0.2709])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank to get some cash\"\n",
    "word = \" bank\"  # gpt tokenizer prepends spaces\n",
    "\n",
    "# Get embedding\n",
    "bank_gpt_embedding = get_word_embedding(sentence, word, gpt_model, gpt_tokenizer)\n",
    "print(\"GPT Embedding for '{}' in relation to cash:\".format(word), bank_gpt_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126b8c6d-f135-4f9c-bf68-d316fc3b61f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Embedding for ' bank' in relation to water: tensor([-0.1299, -0.3162, -1.0468,  0.1864,  0.2709])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I went to the bank of the river\"\n",
    "word = \" bank\"\n",
    "\n",
    "# Same embedding for \" bank\" because all words are the same before \" bank\"\n",
    "river_gpt_embedding = get_word_embedding(sentence, word, gpt_model, gpt_tokenizer)\n",
    "print(\"GPT Embedding for '{}' in relation to water:\".format(word), river_gpt_embedding[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07c7a00e-ccb4-49a0-81d6-97cb9fbb522e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# They are the same embedding!!!\n",
    "(bank_gpt_embedding == river_gpt_embedding).all().item()\n",
    "# Note I specifically designed the sentences to have the EXACT same tokens preceding bank.\n",
    "#  only the tokens after bank are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da4928-4c86-4c70-90f0-8b67d2feac03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
